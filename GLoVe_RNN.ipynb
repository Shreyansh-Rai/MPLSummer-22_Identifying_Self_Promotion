{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErzwA4SlmWaq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data=pd.read_csv('400sentences.csv',sep=\";\") \n",
        "#\n",
        "data = pd.read_csv('sentiment_tweets3.csv') #Testing with some other dataset to see if the problem is with data or model.\n",
        "# data['ans'] = data['ans'].str.lower()\n",
        "data.rename(columns = {\"message to examine\" : \"ans\" , \"label (depression result)\" : \"issp\"}, inplace = True)\n",
        "data.drop(['Index'], axis=1, inplace = True)\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "T4x-7xDum_TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ab36de-4d33-4fd3-ce1d-932c743ffe75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 ans  issp\n",
            "0  just had a real good moment. i missssssssss hi...     0\n",
            "1         is reading manga  http://plurk.com/p/mzp1e     0\n",
            "2  @comeagainjen http://twitpic.com/2y2lx - http:...     0\n",
            "3  @lapcat Need to send 'em to my accountant tomo...     0\n",
            "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "#              \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "#              \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "#              \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "#              \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "#              \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "#              \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "#              \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "#              \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "#              \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "#              \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "stopwords = []"
      ],
      "metadata": {
        "id": "nEnQLUP1niB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(data):\n",
        "  data['ans without stopwords'] = data['ans'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result\n",
        "    \n",
        "data_without_stopwords = remove_stopwords(data)\n",
        "data_without_stopwords['clean_ans']= data_without_stopwords['ans without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_ans'] = data_without_stopwords['clean_ans'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O0E4i7knl-7",
        "outputId": "5196219d-425e-4516-97f9-c128c1d52ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans_list = []\n",
        "cleanans = data_without_stopwords['clean_ans']\n",
        "for i in range(len(data_without_stopwords['clean_ans'])):\n",
        "  ans_list.append(cleanans[i])\n",
        " \n",
        "issp = data_without_stopwords['issp']\n",
        "#Checking\n",
        "for i in range(int(len(cleanans)/40)) :\n",
        "  print(cleanans[i],\" --- \", issp[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liqP9MZ4oHd2",
        "outputId": "36babd08-0327-4732-88e9-dce1f2e73786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "just had a real good moment  i missssssssss him so much   ---  0\n",
            "is reading manga http   plurk com p mzp1e  ---  0\n",
            " comeagainjen http   twitpic com 2y2lx   http   www youtube com watch v zoGfqvh2ME8  ---  0\n",
            " lapcat Need to send  em to my accountant tomorrow  Oddly  I wasn t even referring to my taxes  Those are supporting evidence  though   ---  0\n",
            "ADD ME ON MYSPACE    myspace com LookThunder  ---  0\n",
            "so sleepy  good times tonight though  ---  0\n",
            " SilkCharm re   nbn as someone already said  does fiber to the home mean we will all at least be regular now  ---  0\n",
            "23 or 24ï¿½C possible today  Nice  ---  0\n",
            "nite twitterville workout in the am  ciao  ---  0\n",
            " daNanner Night  darlin   Sweet dreams to you  ---  0\n",
            "Good morning everybody   ---  0\n",
            "Finally  I just created my WordPress Blog  There s already a blog up on the Seattle Coffee Community     http   tinyurl com c5uufd  ---  0\n",
            "kisha they cnt get over u til they get out frm under u just remember ur on top  ---  0\n",
            " nicolerichie Yes i remember that band  It was Awesome  Will you please reply  ---  0\n",
            "I really love reflections and shadows  ---  0\n",
            " blueaero ooo it s fantasy  i like fantasy novels will check it out  ---  0\n",
            " rokchic28 no probs  I sell nothing other than my blog http   snedwan com I ll have to get a listen to your band  on iTunes   ---  0\n",
            " shipovalov  quot NOKLA connecting people quot                      ---  0\n",
            "Once again stayed up to late and have to start too early It is a good thing I like my job  ---  0\n",
            " Kal Penn I just read about your new job  CONGRATULATIONS  That s fantastic   ---  0\n",
            "haven t been able to sleep at ALL  i think i ll watch Ugly Betty online   ---  0\n",
            "woo thanks ron and steeve for following me yeow i have folowerssss haha p s i wanna got to the ellen show  ---  0\n",
            " aidenchan yeah sure but its my sister s so take EXTRA gd care  ---  0\n",
            " sian the mouse yay  a duck  if i want anything watching me it d be a duck  lol  ---  0\n",
            "smaaack that ass  hahhahahaa i make myself laugh   oOooOh sleeeep  ahha g niite   ---  0\n",
            "woo  its late  haha goodnight twitterverse  xoxo  ---  0\n",
            "Looking forward to the meeting with Pastor Kong and JW later   ---  0\n",
            " doubleickey u know those minichocolates in the shape of liquor bottles  with liqour inside em  ---  0\n",
            "Testing to see if twitter works thro facebook  ---  0\n",
            "NIGHT babies  Got a VH1 thing in the am Check out my pics  http   twitpic com 2y57u http   twitpic com 2xzl1 http   twitpic com 2y5s2  ---  0\n",
            "got the magic numbers and is thanking y all for the support  ---  0\n",
            "it s cold  man am i loving this weather  ---  0\n",
            "Ok guys   we ve officially launched new languages  Swedish and  Russian   really fun  if you ask me  www surveypirate com  ---  0\n",
            "The lady who bought the bracelet pictured as my twitter page background is still wearing it a week later    hasn t taken it off  Likes it  ---  0\n",
            "  DwanB i ate filet american this morning and i cant see your pic on mobile twitter  ---  0\n",
            "booked my hair appointment  ---  0\n",
            "My Report Was  English  B   Modern History  A   Geography  B  Maths B  B   Accounting  A and IPT  A  ---  0\n",
            " DTPHULP lol  me too     You do know that the sound of your voice is great   We only need to do some euh fine tuning     ---  0\n",
            "Cupcake heaven  http   ilovecupcakes co za  check out the shop  nice  design  weird contact info popup tho   ---  0\n",
            "Bought the MH bundle  Create a task called  quot Mario quot  or  quot Star Wars quot  in  quot The Hit List quot   Make sure your sound is on and complete the tasks   ---  0\n",
            "someone turn on the shower please    ---  0\n",
            " frumousme yeah there are so many of us angry feeters Tim s THAT good lol    I have been good I go on I just havent posted for a while  ---  0\n",
            " Carly109 love the new song  and the chorus is real nice and catchy  gud job  who did the track and recording jordan   ---  0\n",
            " TayJasper alrite thanxx  ---  0\n",
            " 889grapevine Looking forward to the new website  ---  0\n",
            " modejunkie awww sweetness  But he s still a cutie   ---  0\n",
            " rowanberry ohhh sending loads of Positive vibes your way  ---  0\n",
            " tcouto Cool stuff   ---  0\n",
            "Celebrating a minor banking triumph  that s banking with a b   Got one to admit it was wrong  ---  0\n",
            " cosmicgirlie Thinking of you  Everything crossed Turn baby turn   ---  0\n",
            " EmmaLight I d forgotten about that We need to do that again sometime   ---  0\n",
            " tommcfly Eclipse is awesome it s better than new moon  ---  0\n",
            "Tired today   drunk husband to be rolled in at 1am with bunch friends for another drink  Noisy lot  ---  0\n",
            " ingorammer well it is definitelly worth trying  you ll notice the difference  But it s not my favorite neither  ---  0\n",
            " mileycyrus good morning Miley  ---  0\n",
            "Finished my first shift and doors are opening already   ---  0\n",
            "Nothing quite like finding good amp settings from a solid state amp  ---  0\n",
            " gee lo is it paid  i was made redundant two weeks ago and need a job big time   ---  0\n",
            "Watching the steam trains go back and forth in Ravenglass   sunny   ---  0\n",
            " nat ski how bout some Steppenwolf   Magic Carpet Ride   ---  0\n",
            " shannanstedman haha maxxie beat whippet  ---  0\n",
            "Yaaaaay  Jac is training my sorcerer to level 35  That means I ll be pwn soon   ---  0\n",
            "My doggy is so cute   ---  0\n",
            " nicharry Tell her Simon  quot who used to be from Tuks FM quot  says Hi  ---  0\n",
            "  WildstarB   Happy Rezday Captain   and that was quite a party   ---  0\n",
            "this car is costing me an arm and a leg  but it s so cute I have to forgive it   ---  0\n",
            "tweeting from cracker barrel  ---  0\n",
            " What Amy Said Phillip Schofield  The Schofe  He s a legend  Amy  you need to follow him he s on my page   ---  0\n",
            "is about to check out his new techno records from juno  ---  0\n",
            " RLN49 Too funny   ---  0\n",
            "i have to go now     make up duty for tomorrow       goodnight to all      ---  0\n",
            " StarrGazr Yes mam  There s nothing like starting the day with a good song and a few dance moves  ---  0\n",
            "going to paint my nails then get some foood  ---  0\n",
            "Is in Athens  ---  0\n",
            " pjakobs as in  someone would figure out how to access the mp3s without actually paying for them   ---  0\n",
            " Toothology oh crap  i m sure they won t dare charge for customer care in India though  ---  0\n",
            "is handmade goodness at the moment xxx  ---  0\n",
            " ImASadGiraffe brownies are good any time of day  ---  0\n",
            "Checking myspace while looking at bands from different states so i can add them as friends on myspace I LOVE MUSIC     ---  0\n",
            "Happy Birthday to my Grandpa  He has 3 cats  but I still love him   ---  0\n",
            " fictionals your nose is clogged  use a plunger then  ---  0\n",
            " inque54 huy  matulog ka na  hahah  CBroom ain t done yet  but it s taking shape  ---  0\n",
            " adamSEO it couldn t have come at a better time  ---  0\n",
            "2 days of school left this week and im beyond excited for saturday      ---  0\n",
            "Just a simple girl  oatmeal makes me really happy in the morning  and the blooming wisteria  ---  0\n",
            " Beverleyknight I m fine  thank you  Keep being beautiful always   ---  0\n",
            " aplusk thats beautiful  what a lovely thing to say  ---  0\n",
            " dougiemcfly Change your name to Michelle   ---  0\n",
            " starboy  yay    well dont i feel spesh   ---  0\n",
            "Another year older today  At least it s sunny out   ---  0\n",
            " kdurose yep  but we fought back well  think it will turn out to be the decisive moment in winning the league again though  ---  0\n",
            " LouisS Thanks  I ve lived in Florida since 1994 and I miss snow  ---  0\n",
            "goin abroaaaaad tomrow   Dubaiiii Can t wait    So long twitters    I only have room for prodigy sorry peeps   ---  0\n",
            " MELindsey lol  he has no shame  ---  0\n",
            " urbanfly do y  mean M C Escher  the painter not the DJ  ---  0\n",
            "  I wish school was like those revision sessions  Classes of 10 in non uniform  able to have a laugh and learn at the same time   ---  0\n",
            "Nothin  like a good book and some spring cleaning  http   www mrsdlightful com 2009 04 food storage and pantry cleaning tips html  ---  0\n",
            " kerryn8 Thanks  appreciate your feedback  ---  0\n",
            "i m listening MUSIC  ---  0\n",
            " mileycyrus hi Mileeey  my friend and I can t wait to your come to Spain  we are so excited  we love all of your songs  all are great  ---  0\n",
            " robotsarecool Another big table touch screen WOOT http   www tuaw com 2009 04 07 illusion labs goes to the big screen   ---  0\n",
            " nikhilnarayanan No  no  You are mistaken  My uncle is the PM of Angamali  Any of these anTWIcs there  and you are gone case   shavam  ---  0\n",
            " jptoto Cause we don t have Gems  ---  0\n",
            "The official result came out  PR won 2 seats whereas BN only 1 seat  Congratulations PR   ---  0\n",
            " glovely Thx for the advice  We are just waiting for the Petosin to kick in  ---  0\n",
            "Im playing hooky from work today  my voice is really gone tho so im   home today  ---  0\n",
            "I love spontaneous road trips  ---  0\n",
            "I d love to tweet all day today but I have work to do that must get done so I ll tweet when I can  God bless everyone   tcot  ---  0\n",
            " Pepperfire Is it Friday yet   How are you baby   tweepletuesday  followfriday  ---  0\n",
            "Am taking advantage of the sunshine and am going to take the dog on the beach for a walk   no work for 12 days    yipeeeee  ---  0\n",
            "    still employed  no trouble there it s other stuff that s not as sweet  ---  0\n",
            "Let s see how well this 2 5 hours of sleep holds me today  I predict a massive slowdown by 14 30  That should be funny   ---  0\n",
            "came back from seeing 17 againn   was gooddd  lt 3  ---  0\n",
            " superhootie Maybe    just maybe   ---  0\n",
            " KimKardashian Sooo I just watched Disaster Movie ABSOLUTLY HILARIOUS    Ur my idol  ---  0\n",
            " kvanduyne I am happy you and mandy had a safe trip  I have never been to VA Beach   Enjoy  ---  0\n",
            " jmacgirl1992 I d sign up for the extra credit  ---  0\n",
            "Falling asleep here  So goodnight everyone  ---  0\n",
            " hwork I ve been living in Twitter API land for too long  over there we call it the oauth buttons http   bit ly 70yRH  ---  0\n",
            "me and my mates are gunna chekk out a movie next week  i really want to see the boat that rocked   ---  0\n",
            " BananaAnna2008  mikequad I TOTALLY AGREE WITH YOU  ANNA    ---  0\n",
            " Wordee Follow us so we can contact you   ---  0\n",
            "I love a good book  ---  0\n",
            "With my sister from another mister  Kayla  ---  0\n",
            "i will be the sun in your sky  i will light your way for all time  promise you  for you i willll    ---  0\n",
            " betty822 that sounds like a pretty good night to me  ---  0\n",
            "according to the rosters  this hockey season won t be so bad after all hah   ---  0\n",
            "Happy Gilmore is on  ---  0\n",
            " nick carter Lmao  I guess its only Friday  My bad  ---  0\n",
            " WayneNH I wish I wasn t following you so I could be your 1 000 follower  Wayne  ---  0\n",
            "Time for a shower and french toast  No  not together   ---  0\n",
            " myucan91 daamnn      im not even going to ask if it was boring   come to hk   ---  0\n",
            "Today is Thunder Over Louisville   the start of the Derby Festival  I love being here for the festivities even if I m not going   ---  0\n",
            "Good mornin folks  I think I ll make a couple of home made egg mcmuffins to go with this excellent coffee on this clear sunny 58  mornin  ---  0\n",
            "thinks that Kellan Lutz is hot when he smokes  ---  0\n",
            "Okay  have torn apart my work  Fresh coffee  amp  peanut butter toast then I ll try and put it back together again  Only less crap this time  ---  0\n",
            "Relaxing before guests come  hope everyone likes the food   I know Morton won t  have made plain rice for him  ---  0\n",
            " SURFislikeaBoss me hair ain t Red its da light its blonde and black   jamesissexy Hey Hotty   firesty who da other girl   ---  0\n",
            "Today is the day  ---  0\n",
            "Shopped Queen St in the sun yesterday  likely the last time for a while  I need to find the SF equivalent of that experience   ---  0\n",
            "Backgammon then a birthday meal for a friend later on  ---  0\n",
            " DonnieWahlberg HOLLA    Just chilling  on my way to buy some maple syrup  mmm     What s up with you  Hope you re having a great morning  ---  0\n",
            " MabelKatz Looks ok now  only bits and bytes  clean with Ho oponopono too    ---  0\n",
            " azcameron serious business  ---  0\n",
            " llllloise    You made na your Twitter  Haha  D Upload a photo  UPDATEEE   ---  0\n",
            " LinaCyrus heyy  aww thanks so much hun you rock  xoxo  ---  0\n",
            " heidimontag heidiii  i love your new single Blackout  amazing  I think you dress amazinggg im so jealous haha  please answer something  ---  0\n",
            " NubianEagle I was tempted this morning  I randomly woke up at 5 30  but I had just fallen asleep after 2  My sanity is more important   ---  0\n",
            " saidthewhale great photographs  saw you guys play at the westjet street party  short set but awesome nonetheless  ---  0\n",
            " amandabynes i really liked it  i m ur  1 fan i loved all of ur movies  especially  she s the man   it s so funny  I LOVE IT   lt 3  ---  0\n",
            " meday right back atchya   Hope you re having a great day   ---  0\n",
            "just got out of the showerrr  myspacing   ---  0\n",
            "is gonna hang out with my two favorite people now  http   plurk com p ovm1q  ---  0\n",
            "pipe down  calling  Bigthangs  ---  0\n",
            " theendtime lmao i love me a good comedy  ---  0\n",
            " KoldCastTV and  beautyboutique Thanks for following   ---  0\n",
            " RealWorldMom  ---  0\n",
            "Twittering   And looking for Miley Cyrus LUv her   xo  ---  0\n",
            " KimKardashian hey kim im a huge fan  ur like my role model and i really hope i can actually meet u one day   ---  0\n",
            "is going outside  ---  0\n",
            " ddlovato oh demi  that sure was a knee slapper   ---  0\n",
            "Is with alyssa  ---  0\n",
            " mystica43229 Hi luv  Sounds like you had a busy day  Hope all went well   ---  0\n",
            "Watching the brady bunch  ---  0\n",
            "going out to the mall once again  ---  0\n",
            "mad at  tacrain and  kylielanejonas for completing our mission without me  but app was so good and very pretty   ---  0\n",
            "I LOVE the sound of breaking glass  Something very cathartic about it    ---  0\n",
            "Boulder creek with gram  ---  0\n",
            " mebrownie09 i love you baby     ---  0\n",
            " gisher I m just the retweeter I personally believe the Tweet Effect  and the weekly purge  will take care of these things for me     ---  0\n",
            " ddlovato Aw  have a safe trip sweety  ill miss you more ox  ---  0\n",
            " LodurZJ Well pizza    but that is good too   ---  0\n",
            "QOTD   quot Hey   I still haven t told you guys the story about the English Heritage fella and how he s lucky to be still alive  quot   yawnerddn  ---  0\n",
            "I m still sitting here  Maybe I ll go get some air  I seriously need help  my life is almost as cluttered as my room   ---  0\n",
            " nakrissimo Can I come  I could use a nice decadent party   ---  0\n",
            "around   ---  0\n",
            " selenagomez I LOVE YOU SELENA GOMEZ    You re so beautiful  You re my role model and my idol  I would be so happy if you reply to me  ---  0\n",
            " sassycat24 My Mommy is here       ---  0\n",
            "Having a beer  amp  corn dog  I know weird combo    the Santa Monica Pier   ---  0\n",
            " Clouds2287 Hm  So I take it the essays are not going so well right now  Perhaps a swap  I have nothing left to lose lol  ---  0\n",
            "tweetup afterparty at genji  ---  0\n",
            "Back to work for me    Twitt ya ll laterz  ---  0\n",
            "going to church  ---  0\n",
            " teh Joker Yeah  now that im done puking crown and coke  ---  0\n",
            " oliverwalton i know im not normally on here but il though il be cool and see what is happening on the world of twitter  ---  0\n",
            "and wife are shopping at the Great Mall in Milpitas  Great prices for us  with the dollar still reasonably low for us     ---  0\n",
            "goiing to reedbox to get some moviies  ---  0\n",
            " sadknob good thing P  amp  K have their day jobs   ---  0\n",
            " capecodgurl and sorry again for spamming   having trouble mashing out multisyllabic words with my hate fingers  ---  0\n",
            "Statesboro fun this a m  and I m off to see the GreenJackets in Augusta tonight   ---  0\n",
            " just kelly The fact that you didn t know the library closed at 6  NOT LAME   ---  0\n",
            " carysss oopssss i forgot to put ypur link at the beginning  it was to you haha in case you didn t realise  Hope you re feeling better  ---  0\n",
            "hi  LoriBlue4508   I would suggest music of my electro project     http   bit ly 12KoF0     free download  amp  have fun cheers  ---  0\n",
            " elicab Aw  Well if u ever feel like flying over 2 con it up i ll help u find a place 2 crash    I once flew 2 London 4 a Buffy con  btw   ---  0\n",
            "just had a fabulous 1 5 hr run in the desert with MIssy and Kaya and is now off to run some errands before buffalo burgers  ---  0\n",
            "going old school   playing super mario brothers   ---  0\n",
            "Heading down to Clear Lake to meet Ken and other Coast Guar Aux for dinner  Hope the roads are clear   not feeling up to rowing  ---  0\n",
            " nicky power if you re truly addicted to twitter  you should link your facebook and your twitter together  update one and it does both  ---  0\n",
            " MichaelTyler in most ways at least at this rate though i may even bake something tonight  who knows     ---  0\n",
            " Kevinmiam Thanks  I ll take inspiration from today s test   ---  0\n",
            " LadyMelancon Hey there   ---  0\n",
            " thethirdrat oh good  thankyou  ---  0\n",
            "Im feeling very peaceful now that my room is clean and ny hair is cut  I think Im ready for a nap   ---  0\n",
            "partying it up tonight at J lounge in downtown LA  Its a nice sunny day in cali   ---  0\n",
            " theroser when you guys come to washington state  you should totally crush that tacoma mall PLEASE  lol  ---  0\n",
            " Meghan xoxo seth mcfarlene is god   ---  0\n",
            " vismajor I m so glad you guys are having such a wonderful weekend   ---  0\n",
            "Goodnight all   ---  0\n",
            " ohhushmusic are you sure bb   ---  0\n",
            " robynsykes i half taught myself half actually learned viva la vida by coldplay  epic song  ---  0\n",
            " SugarHustler hehe u are funny  follow me  ---  0\n",
            "watching NCIS  Is it the grey hair that makes Mark Harmon so attractive  I think so   ---  0\n",
            "ready for some PATRON  in Hollywood for Phathead s bday  ---  0\n",
            " laylakayleigh i have to go skydiving  ill let you know next the time im in town  ---  0\n",
            " sambasel nothing  ---  0\n",
            " TalulaKim I have the yearbook in the closet I ll look it up 2moro if u are still curious  Um  where did  Ki6bjv go to school exactly LOL  ---  0\n",
            "New Osalto blog post   http   tinyurl com dnbrw3 Enjoy  ---  0\n",
            "blasting the Across the Universe soundtrack  ---  0\n",
            " AngMoGirl oh don t worry  not gonna be too bad cos its a Sunday   ---  0\n",
            " starpadilla lol so  I don t really understand Twitter quite yet  But I JUST got your reply to Chipotle  And thats cool  ---  0\n",
            " Billy3G All the cool people were  herebeforeoprah  ---  0\n",
            "i had a fun night  got to see  nevershoutnever and andy from  holidayparade  yaye  then  waitrewindthat took me to ihop yum   ---  0\n",
            "Oliver Long getting ready to come on  ---  0\n",
            " britneyspears I was at the show last night   AMAZING  So glad I was able to go    ---  0\n",
            " zenzie386 Yes NYC has it s own way of love hating you    http   twitpic com 3ky08  ---  0\n",
            " ResPres BTW Meant to tell you earlier  sweet shirt  to wear Afflication UFC shirts  still waiting on my cool card to get auth to wear  ---  0\n",
            " Exoticqtee u a learn   ---  0\n",
            "skyping is such endless fun  ---  0\n",
            "Bali in july japan   when s a good time to go to japan  anyone   ---  0\n",
            " britneyspears thanks for following me back  ---  0\n",
            " azthunderpony Nice  I think I ll get to sleep so I ll have enough energy to enjoy my horsey day   ---  0\n",
            "just joined up  can t sleep  mon tue trackday at NJMP on the CBR600RR http   www njmotorsportspark com tracks html    thunderbolt  ---  0\n",
            " Dili   thank you   huge hugs    ---  0\n",
            " fureousangel I recently did a Matrix Trilogy sitting  that was tiring but awesome  Matrix Trilogy is my favorite sci fi film story   ---  0\n",
            " audball xo Totally agree with you on Beyonce  She s stupid     Ali Larter is WHERE IT S AT   ---  0\n",
            " JimAlger Don t forget  parents often think of their offspring as about 12 yo  ---  0\n",
            " SophietheCocker Wardrobes are often made of cheese  so you can eat them   ---  0\n",
            "went 2 wallyworld today had an awesome time getting a kewl easter basket and a nitelite for my computer  ---  0\n",
            " KarenCivil okay  he just texted me saying that he d wake up me up lol    if he doesnt I call you at 1PM your time  thx Karen  ---  0\n",
            "  now Sleep  ---  0\n",
            "Watching the IDNHU vid   ---  0\n",
            " Lizinhollywood Can t wait     ---  0\n",
            " RoxxiNikki happy birthday  Take plenty of pics video so you ll remember what you did later on   ---  0\n",
            "good night tonight   my journey on twit ends here until tomorrow see ya tomorrow  ---  0\n",
            " Oddessy congrats you are now cooler than me  Happy Birthday Miss Lovely   ---  0\n",
            "night twittz  Jus came home from partying loved it   hella tired Allergic to cats ew  All irritated  ---  0\n",
            "Happy easter     Everyone  ---  0\n",
            " janinealino janine whoa dude hahah u really put the things i sent u sa fb ahhaha  gee tnx janine  ---  0\n",
            " NeilDenny hehe yep I love car boot    Never usually buy much heh  ---  0\n",
            " iamdiddy LOve you DIDDY Diddy live  gt  http   bit ly BeN2t  ---  0\n",
            "I VE FINISHED THE  EAT ME  DRINK ME  BADGES          gt  http   twitpic com 3l3i1  lt      Look here  ---  0\n",
            "Just about ready to go to bed  It was a long day today  Good night   ---  0\n",
            " authorlisalogan oooh cool cool thank you very much for that information  ---  0\n",
            " KnightTim I love you too  ---  0\n",
            " hannahvictorius we should  We ll organise it properly next time  Glad you enjoyed it  ---  0\n",
            " tourscotland     got it     you must be rechargeable  ---  0\n",
            " com4myst blgspt thanks  ---  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test,Y_train, Y_test = train_test_split(cleanans, issp, test_size=0.2, random_state = 45)"
      ],
      "metadata": {
        "id": "L6lx5MTTpEq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test, \"\\n\", Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y_otzIDpmh9",
        "outputId": "ebf180f6-cee9-48b0-956a-e4f54158405a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7701          is going to get contact lenses    hopefully\n",
            "3884    aches after working out    off to my brothers ...\n",
            "2959     ScruffyPanther your like me too many baby gen...\n",
            "1059    Old enough to know better  young enough to not...\n",
            "4235    all of my friends are busy with their test s  ...\n",
            "                              ...                        \n",
            "6775     ARobotsDeath I d love that superpower  do you...\n",
            "866           pedrocs aahh cuddy      power truly is sexy\n",
            "4701                  CruncyK Night  Kevin  Sweet Dreams \n",
            "9099    My mom told me about her depression and how sh...\n",
            "8998    Try to keep up with social activities even if ...\n",
            "Name: clean_ans, Length: 2063, dtype: object \n",
            " 7701    0\n",
            "3884    0\n",
            "2959    0\n",
            "1059    0\n",
            "4235    0\n",
            "       ..\n",
            "6775    0\n",
            "866     0\n",
            "4701    0\n",
            "9099    1\n",
            "8998    1\n",
            "Name: issp, Length: 2063, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "#Mapping of the words to their index. important later for glove.\n",
        "words_to_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "tk77shcOqrxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  #Code copied to return word_to_vec_map. similar to Seq Model course on coursera.\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "metadata": {
        "id": "bf6nZcCRrILq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGUPVESFtNGN",
        "outputId": "f629db56-2a64-4405-aa25-aab0caab26e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_vec_map = read_glove_vector('gdrive/MyDrive/glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "FzdeKU6ctiug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = 150\n",
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0] #getting the shape by testing random word.\n",
        "#Standard emb matrix W*Onehot = emb vec\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "#each row is going to be a new word of emb vec len.\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None and index<vocab_len:\n",
        "    emb_matrix[index, :] = embedding_vector #set that index in the emb matrix to the glove vector.\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)\n",
        "# standard emb layer that takes in all words from vocab and uses the emb matrix."
      ],
      "metadata": {
        "id": "5LRX5snet2W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def issp_pred1(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "  \n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model\n",
        "def issp_pred2(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  # X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  bl = tf.keras.layers.Bidirectional(LSTM(128, return_sequences=True))\n",
        "\n",
        "  X = bl(embeddings)\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  x = Dense(10, activation=\"relu\")(X)\n",
        "\n",
        "  # X = Dropout(0.5)(X)\n",
        "  X = Dropout(0.5)(X)\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model\n",
        "\n",
        "def issp_pred3(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  # X = LSTM(128)(X)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "k6FgG1kAwLBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ],
      "metadata": {
        "id": "AkW2BodFwZIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = issp_pred1((maxLen,))\n",
        "model2 = issp_pred2((maxLen,))\n",
        "model3 = issp_pred3((maxLen,))"
      ],
      "metadata": {
        "id": "Zq25MJ4fxJ1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate = 0.007)\n",
        "\n",
        "model1.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model1.fit(X_train_indices, Y_train, batch_size=64, epochs=20)\n",
        "\n",
        "model2.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train_indices, Y_train, batch_size=64, epochs=20) \n",
        "\n",
        "model3.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train_indices, Y_train, batch_size=256, epochs=20)"
      ],
      "metadata": {
        "id": "6pExHjEzxslX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1f4950-1c6d-4852-c7c2-43dd31ed6035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "129/129 [==============================] - 8s 28ms/step - loss: 0.5500 - accuracy: 0.7730\n",
            "Epoch 2/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5360 - accuracy: 0.7760\n",
            "Epoch 3/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5371 - accuracy: 0.7759\n",
            "Epoch 4/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5402 - accuracy: 0.7760\n",
            "Epoch 5/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5397 - accuracy: 0.7760\n",
            "Epoch 6/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5378 - accuracy: 0.7760\n",
            "Epoch 7/20\n",
            "129/129 [==============================] - 3s 27ms/step - loss: 0.5359 - accuracy: 0.7760\n",
            "Epoch 8/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5364 - accuracy: 0.7760\n",
            "Epoch 9/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5358 - accuracy: 0.7760\n",
            "Epoch 10/20\n",
            "129/129 [==============================] - 5s 38ms/step - loss: 0.5362 - accuracy: 0.7760\n",
            "Epoch 11/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5351 - accuracy: 0.7760\n",
            "Epoch 12/20\n",
            "129/129 [==============================] - 4s 30ms/step - loss: 0.5343 - accuracy: 0.7760\n",
            "Epoch 13/20\n",
            "129/129 [==============================] - 6s 46ms/step - loss: 0.5341 - accuracy: 0.7760\n",
            "Epoch 14/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5343 - accuracy: 0.7760\n",
            "Epoch 15/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5356 - accuracy: 0.7760\n",
            "Epoch 16/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5341 - accuracy: 0.7760\n",
            "Epoch 17/20\n",
            "129/129 [==============================] - 4s 27ms/step - loss: 0.5348 - accuracy: 0.7760\n",
            "Epoch 18/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5356 - accuracy: 0.7760\n",
            "Epoch 19/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5332 - accuracy: 0.7761\n",
            "Epoch 20/20\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.5342 - accuracy: 0.7760\n",
            "Epoch 1/20\n",
            "129/129 [==============================] - 6s 20ms/step - loss: 0.2734 - accuracy: 0.8940\n",
            "Epoch 2/20\n",
            "129/129 [==============================] - 3s 24ms/step - loss: 0.0944 - accuracy: 0.9777\n",
            "Epoch 3/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0314 - accuracy: 0.9943\n",
            "Epoch 4/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0270 - accuracy: 0.9959\n",
            "Epoch 5/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0304 - accuracy: 0.9951\n",
            "Epoch 6/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0249 - accuracy: 0.9962\n",
            "Epoch 7/20\n",
            "129/129 [==============================] - 4s 30ms/step - loss: 0.0224 - accuracy: 0.9968\n",
            "Epoch 8/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0258 - accuracy: 0.9963\n",
            "Epoch 9/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0225 - accuracy: 0.9967\n",
            "Epoch 10/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0214 - accuracy: 0.9969\n",
            "Epoch 11/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0203 - accuracy: 0.9969\n",
            "Epoch 12/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0198 - accuracy: 0.9968\n",
            "Epoch 13/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0174 - accuracy: 0.9969\n",
            "Epoch 14/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0167 - accuracy: 0.9969\n",
            "Epoch 15/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0151 - accuracy: 0.9968\n",
            "Epoch 16/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0133 - accuracy: 0.9971\n",
            "Epoch 17/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0118 - accuracy: 0.9976\n",
            "Epoch 18/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 19/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0097 - accuracy: 0.9983\n",
            "Epoch 20/20\n",
            "129/129 [==============================] - 3s 20ms/step - loss: 0.0078 - accuracy: 0.9985\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 4s 36ms/step - loss: 0.5758 - accuracy: 0.7631\n",
            "Epoch 2/20\n",
            "33/33 [==============================] - 1s 33ms/step - loss: 0.5168 - accuracy: 0.7723\n",
            "Epoch 3/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.5037 - accuracy: 0.7753\n",
            "Epoch 4/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.3965 - accuracy: 0.8210\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.2534 - accuracy: 0.8902\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1880 - accuracy: 0.9247\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1484 - accuracy: 0.9471\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1175 - accuracy: 0.9606\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1217 - accuracy: 0.9576\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1052 - accuracy: 0.9653\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0971 - accuracy: 0.9670\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0931 - accuracy: 0.9692\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0834 - accuracy: 0.9729\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0822 - accuracy: 0.9725\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.1095 - accuracy: 0.9653\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0900 - accuracy: 0.9722\n",
            "Epoch 17/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0814 - accuracy: 0.9747\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0761 - accuracy: 0.9761\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0802 - accuracy: 0.9740\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 1s 34ms/step - loss: 0.0754 - accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f134e1a7310>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
        "model1.evaluate(X_test_indices, Y_test)\n",
        "model2.evaluate(X_test_indices, Y_test)\n",
        "model3.evaluate(X_test_indices, Y_test)"
      ],
      "metadata": {
        "id": "j5Gvpnzp0ZCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fee742-91fd-43c3-8a49-66722d3dc1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 2s 13ms/step - loss: 0.5345 - accuracy: 0.7741\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.0404 - accuracy: 0.9936\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.0522 - accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0521932952105999, 0.982537031173706]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_list_idx = tokenizer.texts_to_sequences(ans_list)\n",
        "def add_score_predictions(reviews_list_idx):\n",
        "\n",
        "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
        "\n",
        "  review_preds = model3.predict(reviews_list_idx)\n",
        "\n",
        "  # pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\n",
        "\n",
        "  for i in range(len(ans_list)) :\n",
        "    print(ans_list[i], \" -- \",np.sum(review_preds[i])/len(review_preds[i]))\n"
      ],
      "metadata": {
        "id": "keGj5o82jDMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_score_predictions(reviews_list_idx)"
      ],
      "metadata": {
        "id": "WF2sJPeCjem8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wNCoelbViiZP"
      }
    }
  ]
}